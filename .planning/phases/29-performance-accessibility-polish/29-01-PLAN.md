---
phase: 29-performance-accessibility-polish
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - convex/programs.ts
  - convex/attendance/queries.ts
  - convex/emails/send.ts
  - convex/matching/compute.ts
  - convex/matching/mutations.ts
autonomous: true

must_haves:
  truths:
    - 'getMyAttendanceHistory, getPendingPrompts, and getMyAttendanceSummary batch-fetch events and orgs via Promise.all with deduped IDs instead of per-record ctx.db.get'
    - "getUsersForMatchAlertBatch, getUsersForWeeklyDigestBatch, getUsersForDailyEventDigestBatch, and getUsersForWeeklyEventDigestBatch use ctx.db.get with Id cast instead of ctx.db.query('users').filter()"
    - 'getProgramParticipants batch-fetches profiles instead of per-participant indexed query'
    - 'Matching compute uses chained scheduled actions (ctx.scheduler.runAfter) with rate limiting between batches and exponential backoff on rate limit errors'
    - 'Each matching batch saves progress via mutation before scheduling the next batch'
    - 'Performance logging (via convex/lib/logging.ts) records read counts in optimized queries and wall-clock time in matching actions'
  artifacts:
    - path: 'convex/attendance/queries.ts'
      provides: 'Batched attendance queries'
      contains: 'new Set'
    - path: 'convex/emails/send.ts'
      provides: 'Batched user lookups with direct ID access'
      contains: 'as Id<"users">'
    - path: 'convex/programs.ts'
      provides: 'Batched participant profile lookups'
      contains: 'new Map'
    - path: 'convex/matching/compute.ts'
      provides: 'Rate-limited chained scheduled action architecture'
      contains: 'ctx.scheduler.runAfter'
    - path: 'convex/matching/mutations.ts'
      provides: 'Incremental batch result saving'
      contains: 'saveBatchResults'
  key_links:
    - from: 'convex/matching/compute.ts'
      to: 'convex/matching/mutations.ts'
      via: 'ctx.runMutation for saving batch results between scheduled actions'
      pattern: "internal\\.matching\\.mutations\\.saveBatchResults"
    - from: 'convex/emails/send.ts'
      to: 'users table'
      via: "ctx.db.get with Id<'users'> cast instead of .query().filter()"
      pattern: "ctx\\.db\\.get\\(\"users\""
---

<objective>
Resolve all N+1 query patterns in hot-path database queries and add rate limiting to matching batch API calls.

Purpose: Ensure database queries scale efficiently for the BAISH pilot (50-100 profiles) and matching compute runs complete reliably without hitting Anthropic rate limits or Convex 10-minute action timeouts.

Output: Optimized convex query functions using two-pass batch pattern (collect IDs, batch fetch, Map lookup), and a chained scheduled action architecture for rate-limited matching.
</objective>

<execution_context>
@/Users/luca/.claude/get-shit-done/workflows/execute-plan.md
@/Users/luca/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/29-performance-accessibility-polish/29-CONTEXT.md
@.planning/phases/29-performance-accessibility-polish/29-RESEARCH.md

@convex/attendance/queries.ts
@convex/emails/send.ts
@convex/programs.ts
@convex/matching/compute.ts
@convex/matching/mutations.ts
@convex/matching/queries.ts
@convex/lib/logging.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Batch N+1 fixes in attendance, emails, and programs queries</name>
  <files>
    convex/attendance/queries.ts
    convex/emails/send.ts
    convex/programs.ts
  </files>
  <action>
Apply the two-pass batch pattern to all N+1 query functions. The pattern is: (1) collect all unique IDs into Sets, (2) batch-fetch with `Promise.all(ids.map(id => ctx.db.get(table, id)))`, (3) build a `Map<string, Doc>` for O(1) lookups. Add performance logging via `import { log } from '../lib/logging'` (or `'./lib/logging'` depending on depth) to each fixed function, logging read counts.

**convex/attendance/queries.ts** - Fix 3 functions:

1. `getMyAttendanceHistory`: After fetching `attendance` records, collect unique `eventId` and `orgId` values into Sets. Batch-fetch events and orgs with `Promise.all`. Build `eventMap` and `orgMap` Maps. Replace per-record `ctx.db.get` with Map lookups. Add log: `log('info', 'getMyAttendanceHistory', { records: attendance.length, batchedEventReads: eventIds.length, batchedOrgReads: orgIds.length })`.

2. `getPendingPrompts`: Same pattern. After fetching prompts, collect unique `eventId` and `orgId` values (filter out undefined orgIds). Batch-fetch. Build Maps. Replace per-prompt `ctx.db.get` calls. Log read counts.

3. `getMyAttendanceSummary`: Same pattern for the `recentRecords` enrichment. Collect unique eventIds and orgIds from the 3 recent records, batch-fetch, build Maps.

**convex/emails/send.ts** - Fix 4 functions that do per-profile user lookups:

1. `getUsersForMatchAlertBatch`: Replace the loop that does `ctx.db.query("users").filter(q => q.eq(q.field("_id"), profile.userId)).first()` per profile. Instead: first filter eligible profiles (those with matchAlerts enabled AND correct timezone hour), then batch-fetch users with `Promise.all(eligible.map(p => ctx.db.get("users", p.userId as Id<"users">)))`. Build result from batched data. This eliminates the full-table-scan filter pattern.

2. `getUsersForWeeklyDigestBatch`: Same fix. Filter eligible profiles (weeklyDigest enabled), batch-fetch users by `ctx.db.get("users", p.userId as Id<"users">)`, build result.

3. `getUsersForDailyEventDigestBatch`: Same fix. Filter profiles with daily event digest frequency + correct timezone hour, then batch-fetch users.

4. `getUsersForWeeklyEventDigestBatch`: Same fix. Filter profiles with weekly event digest frequency, batch-fetch users.

Import `Id` type from `"../_generated/dataModel"` (already imported in some files). Cast `profile.userId as Id<"users">` for the `ctx.db.get` call -- this is safe because auth-generated user IDs are always valid document IDs (per CONTEXT.md decision).

Add `import { log } from '../lib/logging'` and log read counts in each fixed function.

**convex/programs.ts** - Fix 1 function:

1. `getProgramParticipants`: Currently does per-participation profile lookup via index. After fetching all participations, collect unique `userId` values, batch-fetch profiles with `Promise.all(userIds.map(userId => ctx.db.query("profiles").withIndex("by_user", q => q.eq("userId", userId)).first()))`. Build a `Map<string, profile>` keyed by userId. Replace per-participant profile lookup with Map get.

Note: `getOrgPrograms` participant counting uses indexed queries per program and is already as efficient as possible without denormalization. Leave it as-is but add a performance log noting the read count: `log('info', 'getOrgPrograms', { programCount: programs.length, participantQueries: programs.length })`.

Import `{ log }` from `'./lib/logging'` in programs.ts.
</action>
<verify>
Run `bun run lint` and `bun run build` -- both should pass with no errors. Verify via grep that NO occurrence of `ctx.db.query("users").filter` with `_id` comparison remains in emails/send.ts. Verify that `new Set` and `new Map` patterns exist in attendance/queries.ts.
</verify>
<done>
All 8 N+1 query patterns are resolved: 3 in attendance/queries.ts use batched event+org lookups, 4 in emails/send.ts use direct ID-based user lookups via ctx.db.get instead of full-table-scan filters, and 1 in programs.ts batches profile lookups. Performance logs record read counts in each optimized function.
</done>
</task>

<task type="auto">
  <name>Task 2: Rate-limited matching with chained scheduled actions</name>
  <files>
    convex/matching/compute.ts
    convex/matching/mutations.ts
  </files>
  <action>
Refactor the matching compute to use chained scheduled actions instead of processing all batches in a single action loop. This prevents Convex 10-minute action timeout and adds rate limiting between Anthropic API calls.

**convex/matching/mutations.ts** - Add new mutation:

Add `saveBatchResults` internal mutation that saves a single batch of match results incrementally (without clearing existing matches first). It should:

- Accept `profileId`, `batchIndex`, `matches` (same validator as existing), `modelVersion`, and `isLastBatch: v.boolean()`
- If `batchIndex === 0`: clear existing matches for the profile first (same logic as existing `clearMatchesForProfile`), then determine which opportunity IDs existed before clearing (for `isNew` calculation)
- Insert the batch's matches, marking `isNew` based on whether the opportunity was in the previous match set
- If `isLastBatch`: no additional action needed (completion is implicit)
- Return `{ savedCount: number }`

**convex/matching/compute.ts** - Refactor into chained architecture:

1. Keep `computeMatchesForProfile` as the entry point, but change it to:
   - Fetch profile and candidate opportunities (same as current)
   - Calculate total batch count: `Math.ceil(opportunities.length / BATCH_SIZE)`
   - If 0 opportunities: clear matches and return (same as current)
   - Build `profileContext` once
   - Schedule the first batch action: `await ctx.scheduler.runAfter(0, internal.matching.compute.processMatchBatch, { profileId, batchIndex: 0, totalBatches, retryCount: 0 })`
   - Return `{ message: "Matching started", totalBatches }`

2. Create new `processMatchBatch` internal action:
   - Args: `profileId: v.id("profiles"), batchIndex: v.number(), totalBatches: v.number(), retryCount: v.number()`
   - Re-fetch profile and opportunities inside this action (each action is a fresh invocation)
   - Slice to get the current batch: `opportunities.slice(batchIndex * BATCH_SIZE, (batchIndex + 1) * BATCH_SIZE)`
   - Call Anthropic API for this batch (same logic as current loop body)
   - Parse and validate response (same Zod validation in shadow mode)
   - Save results via `ctx.runMutation(internal.matching.mutations.saveBatchResults, { profileId, batchIndex, matches: [...], modelVersion: MODEL_VERSION, isLastBatch: batchIndex + 1 >= totalBatches })`
   - If more batches remain: schedule next batch with a 1-second delay for rate limiting: `await ctx.scheduler.runAfter(1000, internal.matching.compute.processMatchBatch, { profileId, batchIndex: batchIndex + 1, totalBatches, retryCount: 0 })`
   - On error: if it looks like a rate limit error (status 429 or message contains "rate"), schedule retry with exponential backoff: `Math.min(1000 * Math.pow(2, retryCount), 60000)` ms delay, incrementing `retryCount`. Cap retries at 10.
   - On non-rate-limit error: log the error and schedule next batch (skip this batch to avoid blocking the entire run).
   - Add wall-clock timing: `const startTime = Date.now()` at start, log duration at end via `log('info', 'processMatchBatch', { batchIndex, totalBatches, durationMs: Date.now() - startTime, matchCount: batchMatches.length })`.

3. Keep the `deduplicateGrowthAreas` function. Growth areas are now handled differently: each batch can store growth areas in the match records or a separate field. For simplicity, keep growth areas aggregation in the final batch save. The `saveBatchResults` mutation can accumulate growth areas on the profile when `isLastBatch` is true.

4. Add a helper function `isRateLimitError(error: unknown): boolean` that checks for 429 status codes or "rate" in the error message string.

Important: Import `internal` from `'../_generated/api'` (already imported). The `processMatchBatch` must be exported as an `internalAction` so it can be referenced via `internal.matching.compute.processMatchBatch`.
</action>
<verify>
Run `bun run lint` and `bun run build` -- both should pass. Verify that `ctx.scheduler.runAfter` appears in compute.ts. Verify that `saveBatchResults` is exported from mutations.ts. Verify that the old synchronous loop (`for (let i = 0; ...`) is replaced with the chained scheduling pattern.
</verify>
<done>
Matching compute uses chained scheduled actions: each batch processes independently within its own action invocation, saves results via mutation, and schedules the next batch with 1-second rate limiting delay. Rate limit errors trigger exponential backoff retries (max 10). No single action runs for more than a few minutes, well within Convex's 10-minute timeout. Performance logging tracks wall-clock time per batch.
</done>
</task>

</tasks>

<verification>
1. `bun run lint` passes with no errors
2. `bun run build` succeeds
3. `grep -r 'ctx.db.query("users").filter' convex/emails/send.ts` returns NO results (full-table-scan eliminated)
4. `grep -c 'new Set\|new Map' convex/attendance/queries.ts` returns >= 6 (Sets and Maps for batch pattern)
5. `grep -c 'ctx.scheduler.runAfter' convex/matching/compute.ts` returns >= 2 (scheduling next batch + retry)
6. `grep 'saveBatchResults' convex/matching/mutations.ts` returns results (new mutation exists)
7. `grep "log(" convex/attendance/queries.ts convex/emails/send.ts convex/programs.ts convex/matching/compute.ts` returns results in all 4 files
</verification>

<success_criteria>

- All N+1 query patterns eliminated: attendance queries batch event+org lookups, email queries use direct ID lookups, program queries batch profile lookups
- Matching compute uses chained scheduled actions with rate limiting (1s between batches) and exponential backoff on 429 errors
- Performance logging records read counts and action duration in all modified functions
- All code typechecks and lints cleanly
  </success_criteria>

<output>
After completion, create `.planning/phases/29-performance-accessibility-polish/29-01-SUMMARY.md`
</output>
